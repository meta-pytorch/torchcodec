{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n.. meta::\n   :description: Learn how to optimize TorchCodec video decoding performance with batch APIs, approximate seeking, multi-threading, and CUDA acceleration.\n\n# TorchCodec Performance Tips and Best Practices\n\nThis tutorial consolidates performance optimization techniques for video\ndecoding with TorchCodec. Learn when and how to apply various strategies\nto increase performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n\nWhen decoding videos with TorchCodec, several techniques can significantly\nimprove performance depending on your use case. This guide covers:\n\n1. **Batch APIs** - Decode multiple frames at once\n2. **Approximate Mode & Keyframe Mappings** - Trade accuracy for speed\n3. **Multi-threading** - Parallelize decoding across videos or chunks\n4. **CUDA Acceleration** - Use GPU decoding for supported formats\n\nWe'll explore each technique and when to use it.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Use Batch APIs When Possible\n\nIf you need to decode multiple frames at once, the batch methods are faster than calling single-frame decoding methods multiple times.\nFor example, :meth:`~torchcodec.decoders.VideoDecoder.get_frames_at` is faster than calling :meth:`~torchcodec.decoders.VideoDecoder.get_frame_at` multiple times.\nTorchCodec's batch APIs reduce overhead and can leverage internal optimizations.\n\n**Key Methods:**\n\nFor index-based frame retrieval:\n\n- :meth:`~torchcodec.decoders.VideoDecoder.get_frames_at` for specific indices\n- :meth:`~torchcodec.decoders.VideoDecoder.get_frames_in_range` for ranges\n\nFor timestamp-based frame retrieval:\n\n- :meth:`~torchcodec.decoders.VideoDecoder.get_frames_played_at` for timestamps\n- :meth:`~torchcodec.decoders.VideoDecoder.get_frames_played_in_range` for time ranges\n\n**When to use:**\n\n- Decoding multiple frames\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For complete examples with runnable code demonstrating batch decoding,\n    iteration, and frame retrieval, see `sphx_glr_generated_examples_decoding_basic_example.py`</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Approximate Mode & Keyframe Mappings\n\nBy default, TorchCodec uses ``seek_mode=\"exact\"``, which performs a :term:`scan` when\nyou create the decoder to build an accurate internal index of frames. This\nensures frame-accurate seeking but takes longer for decoder initialization,\nespecially on long videos.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Approximate Mode**\n\nSetting ``seek_mode=\"approximate\"`` skips the initial :term:`scan` and relies on the\nvideo file's metadata headers. This dramatically speeds up\n:class:`~torchcodec.decoders.VideoDecoder` creation, particularly for long\nvideos, but may result in slightly less accurate seeking in some cases.\n\n\n**Which mode should you use:**\n\n- If you care about exactness of frame seeking, use \u201cexact\u201d.\n- If the video is long and you're only decoding a small amount of frames, approximate mode should be faster.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Custom Frame Mappings**\n\nFor advanced use cases, you can pre-compute a custom mapping between desired\nframe indices and actual keyframe locations. This allows you to speed up :class:`~torchcodec.decoders.VideoDecoder`\ninstantiation while maintaining the frame seeking accuracy of ``seek_mode=\"exact\"``\n\n**When to use:**\n\n- Frame accuracy is critical, so you cannot use approximate mode\n- You can preprocess videos once and then decode them many times\n\n**Performance impact:** speeds up decoder instantiation, similarly to ``seek_mode=\"approximate\"``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For complete benchmarks showing actual speedup numbers, accuracy comparisons,\n    and implementation examples, see `sphx_glr_generated_examples_decoding_approximate_mode.py`\n    and `sphx_glr_generated_examples_decoding_custom_frame_mappings.py`</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Multi-threading for Parallel Decoding\n\nWhen decoding multiple videos or decoding a large number of frames from a single video, there are a few parallelization strategies to speed up the decoding process:\n\n- **FFmpeg-based parallelism** - Using FFmpeg's internal threading capabilities for intra-frame parallelism, where parallelization happens within individual frames rather than across frames. For that, use the `num_ffmpeg_threads` parameter of the :class:`~torchcodec.decoders.VideoDecoder`\n- **Multiprocessing** - Distributing work across multiple processes\n- **Multithreading** - Using multiple threads within a single process\n\nYou can use both multiprocessing and multithreading to decode multiple videos in parallel, or to decode a single long video in parallel by splitting it into chunks.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For complete examples comparing\n    sequential, ffmpeg-based parallelism, multi-process, and multi-threaded approaches, see\n    `sphx_glr_generated_examples_decoding_parallel_decoding.py`</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. CUDA Acceleration\n\nTorchCodec supports GPU-accelerated decoding using NVIDIA's hardware decoder\n(NVDEC) on supported hardware. This keeps decoded tensors in GPU memory,\navoiding expensive CPU-GPU transfers for downstream GPU operations.\n\n### **Recommended: use the Beta Interface!!**\n\nWe recommend you use the new \"beta\" CUDA interface which is significantly faster than the previous one, and supports the same features:\n\n```python\nwith set_cuda_backend(\"beta\"):\n    decoder = VideoDecoder(\"file.mp4\", device=\"cuda\")\n```\n**When to use:**\n\n- Decoding large resolution videos\n- Large batch of videos saturating the CPU\n\n**When NOT to use:**\n\n- You need bit-exact results with CPU decoding\n- Small resolution videos and the PCI-e transfer latency is large\n- GPU is already busy and CPU is idle\n\n**Performance impact:** CUDA decoding can significantly outperform CPU decoding,\nespecially for high-resolution videos and when decoding a lot of frames.\nActual speedup varies by hardware, resolution, and codec.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Checking for CPU Fallback**\n\nIn some cases, CUDA decoding may silently fall back to CPU decoding when the\nvideo codec or format is not supported by NVDEC. You can detect this using\nthe :attr:`~torchcodec.decoders.VideoDecoder.cpu_fallback` attribute:\n\n```python\nwith set_cuda_backend(\"beta\"):\n    decoder = VideoDecoder(\"file.mp4\", device=\"cuda\")\n\n# Print detailed fallback status\nprint(decoder.cpu_fallback)\n```\n<div class=\"alert alert-info\"><h4>Note</h4><p>The timing of when you can detect CPU fallback differs between backends:\n    with the **FFmpeg backend**, you can only check fallback status after decoding at\n    least one frame, because FFmpeg determines codec support lazily during decoding;\n    with the **BETA backend**, you can check fallback status immediately after\n    decoder creation, as the backend checks codec support upfront.\n\n    For installation instructions, detailed examples, and visual comparisons\n    between CPU and CUDA decoding, see `sphx_glr_generated_examples_decoding_basic_cuda_example.py`</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nTorchCodec offers multiple performance optimization strategies, each suited to\ndifferent scenarios. Use batch APIs for multi-frame decoding, approximate mode\nfor faster initialization, parallel processing for high throughput, and CUDA\nacceleration to offload the CPU.\n\nThe best results often come from combining techniques. Profile your specific\nuse case and apply optimizations incrementally, using the benchmarks in the\nlinked examples as a guide.\n\nFor more information, see:\n\n- `sphx_glr_generated_examples_decoding_basic_example.py` - Basic decoding examples\n- `sphx_glr_generated_examples_decoding_approximate_mode.py` - Approximate mode benchmarks\n- `sphx_glr_generated_examples_decoding_custom_frame_mappings.py` - Custom frame mappings\n- `sphx_glr_generated_examples_decoding_parallel_decoding.py` - Parallel decoding strategies\n- `sphx_glr_generated_examples_decoding_basic_cuda_example.py` - CUDA acceleration guide\n- :class:`torchcodec.decoders.VideoDecoder` - Full API reference\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}