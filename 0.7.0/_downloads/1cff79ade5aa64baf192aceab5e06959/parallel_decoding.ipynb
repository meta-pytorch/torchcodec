{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Parallel video decoding: multi-processing and multi-threading\n\nIn this tutorial, we'll explore different approaches to parallelize video\ndecoding of a large number of frames from a single video. We'll compare three\nparallelization strategies:\n\n1. **FFmpeg-based parallelism**: Using FFmpeg's internal threading capabilities\n2. **Joblib multiprocessing**: Distributing work across multiple processes\n3. **Joblib multithreading**: Using multiple threads within a single process\n\nWe'll use [joblib](https://joblib.readthedocs.io/en/latest/) for\nparallelization, as it provides very convenient APIs for distributing work\nacross multiple processes or threads. But this is just one of many ways to\nparallelize work in Python. You can absolutely use a different thread or process\npool manager.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's first define some utility functions for benchmarking and data\nprocessing.  We'll also download a video and create a longer version by\nrepeating it multiple times. This simulates working with long videos that\nrequire efficient processing. You can ignore that part and jump right below to\n`start_parallel_decoding`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import List\nimport torch\nimport requests\nimport tempfile\nfrom pathlib import Path\nimport subprocess\nfrom time import perf_counter_ns\nfrom datetime import timedelta\n\nfrom joblib import Parallel, delayed, cpu_count\nfrom torchcodec.decoders import VideoDecoder\n\n\ndef bench(f, *args, num_exp=3, warmup=1, **kwargs):\n    \"\"\"Benchmark a function by running it multiple times and measuring execution time.\"\"\"\n    for _ in range(warmup):\n        f(*args, **kwargs)\n\n    times = []\n    for _ in range(num_exp):\n        start = perf_counter_ns()\n        result = f(*args, **kwargs)\n        end = perf_counter_ns()\n        times.append(end - start)\n\n    return torch.tensor(times).float(), result\n\n\ndef report_stats(times, unit=\"s\"):\n    \"\"\"Report median and standard deviation of benchmark times.\"\"\"\n    mul = {\n        \"ns\": 1,\n        \"\u00b5s\": 1e-3,\n        \"ms\": 1e-6,\n        \"s\": 1e-9,\n    }[unit]\n    times = times * mul\n    std = times.std().item()\n    med = times.median().item()\n    print(f\"median = {med:.2f}{unit} \u00b1 {std:.2f}\")\n    return med\n\n\ndef split_indices(indices: List[int], num_chunks: int) -> List[List[int]]:\n    \"\"\"Split a list of indices into approximately equal chunks.\"\"\"\n    chunk_size = len(indices) // num_chunks\n    chunks = []\n\n    for i in range(num_chunks - 1):\n        chunks.append(indices[i * chunk_size:(i + 1) * chunk_size])\n\n    # Last chunk may be slightly larger\n    chunks.append(indices[(num_chunks - 1) * chunk_size:])\n    return chunks\n\n\ndef generate_long_video(temp_dir: str):\n    # Video source: https://www.pexels.com/video/dog-eating-854132/\n    # License: CC0. Author: Coverr.\n    url = \"https://videos.pexels.com/video-files/854132/854132-sd_640_360_25fps.mp4\"\n    response = requests.get(url, headers={\"User-Agent\": \"\"})\n    if response.status_code != 200:\n        raise RuntimeError(f\"Failed to download video. {response.status_code = }.\")\n\n    short_video_path = Path(temp_dir) / \"short_video.mp4\"\n    with open(short_video_path, 'wb') as f:\n        for chunk in response.iter_content():\n            f.write(chunk)\n\n    # Create a longer video by repeating the short one 50 times\n    long_video_path = Path(temp_dir) / \"long_video.mp4\"\n    ffmpeg_command = [\n        \"ffmpeg\", \"-y\",\n        \"-stream_loop\", \"49\",  # repeat video 50 times\n        \"-i\", str(short_video_path),\n        \"-c\", \"copy\",\n        str(long_video_path)\n    ]\n    subprocess.run(ffmpeg_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    return short_video_path, long_video_path\n\n\ntemp_dir = tempfile.mkdtemp()\nshort_video_path, long_video_path = generate_long_video(temp_dir)\n\ndecoder = VideoDecoder(long_video_path, seek_mode=\"approximate\")\nmetadata = decoder.metadata\n\nshort_duration = timedelta(seconds=VideoDecoder(short_video_path).metadata.duration_seconds)\nlong_duration = timedelta(seconds=metadata.duration_seconds)\nprint(f\"Original video duration: {int(short_duration.total_seconds() // 60)}m{int(short_duration.total_seconds() % 60):02d}s\")\nprint(f\"Long video duration: {int(long_duration.total_seconds() // 60)}m{int(long_duration.total_seconds() % 60):02d}s\")\nprint(f\"Video resolution: {metadata.width}x{metadata.height}\")\nprint(f\"Average FPS: {metadata.average_fps:.1f}\")\nprint(f\"Total frames: {metadata.num_frames}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Frame sampling strategy\n\nFor this tutorial, we'll sample a frame every 2 seconds from our long video.\nThis simulates a common scenario where you need to process a subset of frames\nfor LLM inference.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TARGET_FPS = 2\nstep = max(1, round(metadata.average_fps / TARGET_FPS))\nall_indices = list(range(0, metadata.num_frames, step))\n\nprint(f\"Sampling 1 frame every {TARGET_FPS} seconds\")\nprint(f\"We'll skip every {step} frames\")\nprint(f\"Total frames to decode: {len(all_indices)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1: Sequential decoding (baseline)\n\nLet's start with a sequential approach as our baseline. This processes\nframes one by one without any parallelization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decode_sequentially(indices: List[int], video_path=long_video_path):\n    \"\"\"Decode frames sequentially using a single decoder instance.\"\"\"\n    decoder = VideoDecoder(video_path, seek_mode=\"approximate\")\n    return decoder.get_frames_at(indices)\n\n\ntimes, result_sequential = bench(decode_sequentially, all_indices)\nsequential_time = report_stats(times, unit=\"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2: FFmpeg-based parallelism\n\nFFmpeg has built-in multithreading capabilities that can be controlled\nvia the ``num_ffmpeg_threads`` parameter. This approach uses multiple\nthreads within FFmpeg itself to accelerate decoding operations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decode_with_ffmpeg_parallelism(\n    indices: List[int],\n    num_threads: int,\n    video_path=long_video_path\n):\n    \"\"\"Decode frames using FFmpeg's internal threading.\"\"\"\n    decoder = VideoDecoder(video_path, num_ffmpeg_threads=num_threads, seek_mode=\"approximate\")\n    return decoder.get_frames_at(indices)\n\n\nNUM_CPUS = cpu_count()\n\ntimes, result_ffmpeg = bench(decode_with_ffmpeg_parallelism, all_indices, num_threads=NUM_CPUS)\nffmpeg_time = report_stats(times, unit=\"s\")\nspeedup = sequential_time / ffmpeg_time\nprint(f\"Speedup compared to sequential: {speedup:.2f}x with {NUM_CPUS} FFmpeg threads.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 3: multiprocessing\n\nProcess-based parallelism distributes work across multiple Python processes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decode_with_multiprocessing(\n    indices: List[int],\n    num_processes: int,\n    video_path=long_video_path\n):\n    \"\"\"Decode frames using multiple processes with joblib.\"\"\"\n    chunks = split_indices(indices, num_chunks=num_processes)\n\n    # loky is a multi-processing backend for joblib: https://github.com/joblib/loky\n    results = Parallel(n_jobs=num_processes, backend=\"loky\", verbose=0)(\n        delayed(decode_sequentially)(chunk, video_path) for chunk in chunks\n    )\n\n    return torch.cat([frame_batch.data for frame_batch in results], dim=0)\n\n\ntimes, result_multiprocessing = bench(decode_with_multiprocessing, all_indices, num_processes=NUM_CPUS)\nmultiprocessing_time = report_stats(times, unit=\"s\")\nspeedup = sequential_time / multiprocessing_time\nprint(f\"Speedup compared to sequential: {speedup:.2f}x with {NUM_CPUS} processes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 4: Joblib multithreading\n\nThread-based parallelism uses multiple threads within a single process.\nTorchCodec releases the GIL, so this can be very effective.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def decode_with_multithreading(\n    indices: List[int],\n    num_threads: int,\n    video_path=long_video_path\n):\n    \"\"\"Decode frames using multiple threads with joblib.\"\"\"\n    chunks = split_indices(indices, num_chunks=num_threads)\n\n    results = Parallel(n_jobs=num_threads, prefer=\"threads\", verbose=0)(\n        delayed(decode_sequentially)(chunk, video_path) for chunk in chunks\n    )\n\n    # Concatenate results from all threads\n    return torch.cat([frame_batch.data for frame_batch in results], dim=0)\n\n\ntimes, result_multithreading = bench(decode_with_multithreading, all_indices, num_threads=NUM_CPUS)\nmultithreading_time = report_stats(times, unit=\"s\")\nspeedup = sequential_time / multithreading_time\nprint(f\"Speedup compared to sequential: {speedup:.2f}x with {NUM_CPUS} threads.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation and correctness check\n\nLet's verify that all methods produce identical results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.testing.assert_close(result_sequential.data, result_ffmpeg.data, atol=0, rtol=0)\ntorch.testing.assert_close(result_sequential.data, result_multiprocessing, atol=0, rtol=0)\ntorch.testing.assert_close(result_sequential.data, result_multithreading, atol=0, rtol=0)\nprint(\"All good!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import shutil\nshutil.rmtree(temp_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}