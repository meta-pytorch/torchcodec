


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<meta content="Learn how to apply transforms during video decoding for improved memory efficiency and performance." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Decoder Transforms: Applying transforms during decoding &mdash; TorchCodec 0.11.0.dev20260211+cu126 Documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom_torchcodec.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Encoding" href="../encoding/index.html" />
    <link rel="prev" title="Decoding with custom frame mappings" href="custom_frame_mappings.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
        <a href='https://pytorch.org/torchcodec/versions.html'> &#x25BC</a>
      </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">TorchCodec documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples and tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec">Installation instructions</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Interactive examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_ref_torchcodec.html">torchcodec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_ref_decoders.html">torchcodec.decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_ref_encoders.html">torchcodec.encoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_ref_samplers.html">torchcodec.samplers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_ref_transforms.html">torchcodec.transforms</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Interactive examples</a> &gt;</li>
        
          <li><a href="index.html">Decoding</a> &gt;</li>
        
      <li>Decoder Transforms: Applying transforms during decoding</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/generated_examples/decoding/transforms.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section class="sphx-glr-example-title" id="decoder-transforms-applying-transforms-during-decoding">
<span id="sphx-glr-generated-examples-decoding-transforms-py"></span><h1>Decoder Transforms: Applying transforms during decoding<a class="headerlink" href="#decoder-transforms-applying-transforms-during-decoding" title="Permalink to this heading">¶</a></h1>
<p>In this example, we will demonstrate how to use the <code class="docutils literal notranslate"><span class="pre">transforms</span></code> parameter of
the <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> class. This parameter allows us
to specify a list of <a class="reference internal" href="../../generated/torchcodec.transforms.DecoderTransform.html#torchcodec.transforms.DecoderTransform" title="torchcodec.transforms.DecoderTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchcodec.transforms.DecoderTransform</span></code></a> or
<a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Transform.html#torchvision.transforms.v2.Transform" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchvision.transforms.v2.Transform</span></code></a> objects. These objects serve as
transform specifications that the <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a>
will apply during the decoding process.</p>
<p>First, a bit of boilerplate, definitions that we will use later. You can skip
ahead to our <a class="reference internal" href="#example-video"><span class="std std-ref">Our example video</span></a> or <a class="reference internal" href="#applying-transforms"><span class="std std-ref">Applying transforms during pre-processing</span></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter_ns" title="time.perf_counter_ns" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">perf_counter_ns</span></a>


<span class="k">def</span><span class="w"> </span><span class="nf">store_video_to</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">local_video_path</span><span class="p">:</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;User-Agent&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">})</span>
    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to download video. </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="w"> </span><span class="si">= }</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">local_video_path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">iter_content</span><span class="p">():</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot</span><span class="p">(</span><span class="n">frames</span><span class="p">:</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span> <span class="n">title</span> <span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.utils</span><span class="w"> </span><span class="kn">import</span> <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid" title="torchvision.utils.make_grid" class="sphx-glr-backref-module-torchvision-utils sphx-glr-backref-type-py-function"><span class="n">make_grid</span></a>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms.v2.functional</span><span class="w"> </span><span class="kn">import</span> <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.functional.to_pil_image.html#torchvision.transforms.v2.functional.to_pil_image" title="torchvision.transforms.v2.functional.to_pil_image" class="sphx-glr-backref-module-torchvision-transforms-v2-functional sphx-glr-backref-type-py-function"><span class="n">to_pil_image</span></a>
        <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cannot plot, please run `pip install torchvision matplotlib`&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <a href="https://matplotlib.org/stable/api/matplotlib_configuration_api.html#matplotlib.rcParams" title="matplotlib.rcParams" class="sphx-glr-backref-module-matplotlib sphx-glr-backref-type-py-data"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span></a><span class="p">[</span><span class="s2">&quot;savefig.bbox&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;tight&quot;</span>
    <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span> <span class="o">/</span> <span class="n">dpi</span><span class="p">,</span> <span class="mi">600</span> <span class="o">/</span> <span class="n">dpi</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="n">dpi</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.functional.to_pil_image.html#torchvision.transforms.v2.functional.to_pil_image" title="torchvision.transforms.v2.functional.to_pil_image" class="sphx-glr-backref-module-torchvision-transforms-v2-functional sphx-glr-backref-type-py-function"><span class="n">to_pil_image</span></a><span class="p">(</span><a href="https://docs.pytorch.org/vision/stable/generated/torchvision.utils.make_grid.html#torchvision.utils.make_grid" title="torchvision.utils.make_grid" class="sphx-glr-backref-module-torchvision-utils sphx-glr-backref-type-py-function"><span class="n">make_grid</span></a><span class="p">(</span><span class="n">frames</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticklabels</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[],</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html#matplotlib.pyplot.tight_layout" title="matplotlib.pyplot.tight_layout" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>
</pre></div>
</div>
<section id="our-example-video">
<span id="example-video"></span><h2>Our example video<a class="headerlink" href="#our-example-video" title="Permalink to this heading">¶</a></h2>
<p>We’ll download a video from the internet and store it locally. We’re
purposefully retrieving a high resolution video to demonstrate using
transforms to reduce the dimensions.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Video source: https://www.pexels.com/video/an-african-penguin-at-the-beach-9140346/</span>
<span class="c1"># Author: Taryn Elliott.</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a> <span class="o">=</span> <span class="s2">&quot;https://videos.pexels.com/video-files/9140346/9140346-uhd_3840_2160_25fps.mp4&quot;</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">temp_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/tempfile.html#tempfile.mkdtemp" title="tempfile.mkdtemp" class="sphx-glr-backref-module-tempfile sphx-glr-backref-type-py-function"><span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">temp_dir</span></a><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;penguin.mp4&quot;</span>
<span class="n">store_video_to</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchcodec.decoders</span><span class="w"> </span><span class="kn">import</span> <span class="n">VideoDecoder</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Penguin video metadata: </span><span class="si">{</span><span class="n">VideoDecoder</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">)</span><span class="o">.</span><span class="n">metadata</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Penguin video metadata: VideoStreamMetadata:
  duration_seconds_from_header: 37.24
  begin_stream_seconds_from_header: 0
  bit_rate: 24879454
  codec: h264
  stream_index: 0
  duration_seconds: 37.24
  begin_stream_seconds: 0
  begin_stream_seconds_from_content: 0
  end_stream_seconds_from_content: 37.24
  width: 3840
  height: 2160
  num_frames_from_header: 931
  num_frames_from_content: 931
  average_fps_from_header: 25
  pixel_aspect_ratio: 0
  rotation: None
  end_stream_seconds: 37.24
  num_frames: 931
  average_fps: 25
</pre></div>
</div>
<p>As shown above, the video is 37 seconds long and has a height of 2160 pixels
and a width of 3840 pixels.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The colloquial way to report the dimensions of this video would be as
3840x2160; that is, (<cite>width</cite>, <cite>height</cite>). In the PyTorch ecosystem, image
dimensions are typically expressed as (<cite>height</cite>, <cite>width</cite>). The remainder
of this tutorial uses the PyTorch convention of (<cite>height</cite>, <cite>width</cite>) to
specify image dimensions.</p>
</div>
</section>
<section id="applying-transforms-during-pre-processing">
<span id="applying-transforms"></span><h2>Applying transforms during pre-processing<a class="headerlink" href="#applying-transforms-during-pre-processing" title="Permalink to this heading">¶</a></h2>
<p>A pre-processing pipeline for videos during training will typically apply a
set of transforms for a variety of reasons. Below is a simple example of
applying TorchVision’s <a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Resize</span></code></a> transform to a single
frame <strong>after</strong> the decoder returns it:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">v2</span>

<span class="n">full_decoder</span> <span class="o">=</span> <span class="n">VideoDecoder</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a> <span class="o">=</span> <span class="n">full_decoder</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">resized_after</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="torchvision.transforms.v2.Resize" class="sphx-glr-backref-module-torchvision-transforms-v2 sphx-glr-backref-type-py-class"><span class="n">v2</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">))(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">)</span>

<span class="n">plot</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">resized_after</span></a><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Resized to 480x640 after decoding&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_transforms_001.png" srcset="../../_images/sphx_glr_transforms_001.png" alt="Resized to 480x640 after decoding" class = "sphx-glr-single-img"/><p>In the example above, <code class="docutils literal notranslate"><span class="pre">full_decoder</span></code> returns a video frame that has the
dimensions (2160, 3840) which is then resized down to (480, 640). But with the
<code class="docutils literal notranslate"><span class="pre">transforms</span></code> parameter of <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> we can
specify for the resize to  happen <strong>during</strong> decoding!</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">resize_decoder</span> <span class="o">=</span> <span class="n">VideoDecoder</span><span class="p">(</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="p">[</span><a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="torchvision.transforms.v2.Resize" class="sphx-glr-backref-module-torchvision-transforms-v2 sphx-glr-backref-type-py-class"><span class="n">v2</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">))]</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">resized_during</span></a> <span class="o">=</span> <span class="n">resize_decoder</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>

<span class="n">plot</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">resized_during</span></a><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Resized to 480x640 during decoding&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_transforms_002.png" srcset="../../_images/sphx_glr_transforms_002.png" alt="Resized to 480x640 during decoding" class = "sphx-glr-single-img"/><p>Importantly, the two frames are not identical, even though we can see they
<em>look</em> very similar:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">abs_diff</span></a> <span class="o">=</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">resized_after</span></a><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">resized_during</span></a><span class="o">.</span><span class="n">float</span><span class="p">())</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">abs_diff</span></a> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor(False)
</pre></div>
</div>
<p>But they’re close enough that models won’t be able to tell a difference:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">abs_diff</span></a> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mf">0.998</span>
</pre></div>
</div>
</section>
<section id="torchcodec-s-relationship-to-torchvision-transforms">
<h2>TorchCodec’s relationship to TorchVision transforms<a class="headerlink" href="#torchcodec-s-relationship-to-torchvision-transforms" title="Permalink to this heading">¶</a></h2>
<p>Notably, in our examples we are passing in TorchVision
<a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Transform.html#torchvision.transforms.v2.Transform" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> objects as our transforms.
However, <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> accepts TorchVision
transforms as a matter of convenience. TorchVision is <strong>not required</strong> to use
decoder transforms.</p>
<p>Every TorchVision transform that <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> accepts
has a complementary transform defined in <a class="reference internal" href="../../api_ref_transforms.html#module-torchcodec.transforms" title="torchcodec.transforms"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torchcodec.transforms</span></code></a>. We
would have gotten the same results if we had passed in the
<a class="reference internal" href="../../generated/torchcodec.transforms.Resize.html#torchcodec.transforms.Resize" title="torchcodec.transforms.Resize"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchcodec.transforms.Resize</span></code></a> object that is a part of TorchCodec.
<a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> accepts both objects as a matter of
convenience and to clarify the relationship between the transforms that TorchCodec
applies and the transforms that TorchVision offers.</p>
<p>While <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> accepts TorchVision transforms as
<em>specifications</em>, it is not actually using the TorchVision implementation of these
transforms. Instead, it is mapping them to equivalent
<a class="reference external" href="https://ffmpeg.org/ffmpeg-filters.html">FFmpeg filters</a>. That is,
<a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchvision.transforms.v2.Resize</span></code></a> and <a class="reference internal" href="../../generated/torchcodec.transforms.Resize.html#torchcodec.transforms.Resize" title="torchcodec.transforms.Resize"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchcodec.transforms.Resize</span></code></a> are mapped to
<a class="reference external" href="https://ffmpeg.org/ffmpeg-filters.html#scale-1">scale</a>; and
<a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.CenterCrop.html#torchvision.transforms.v2.CenterCrop" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchvision.transforms.v2.CenterCrop</span></code></a> and <a class="reference internal" href="../../generated/torchcodec.transforms.CenterCrop.html#torchcodec.transforms.CenterCrop" title="torchcodec.transforms.CenterCrop"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchcodec.transforms.CenterCrop</span></code></a> are mapped to
<a class="reference external" href="https://ffmpeg.org/ffmpeg-filters.html#crop">crop</a>.</p>
<p>The relationships we ensure between TorchCodec <a class="reference internal" href="../../generated/torchcodec.transforms.DecoderTransform.html#torchcodec.transforms.DecoderTransform" title="torchcodec.transforms.DecoderTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoderTransform</span></code></a> objects
and TorchVision <a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Transform.html#torchvision.transforms.v2.Transform" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> objects are:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>The names are the same.</p></li>
<li><p>Default behaviors are the same.</p></li>
<li><p>The parameters for the <a class="reference internal" href="../../generated/torchcodec.transforms.DecoderTransform.html#torchcodec.transforms.DecoderTransform" title="torchcodec.transforms.DecoderTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoderTransform</span></code></a>
object are a subset of the TorchVision <a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Transform.html#torchvision.transforms.v2.Transform" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a>
object.</p></li>
<li><p>Parameters with the same name control the same behavior and accept a
subset of the same types.</p></li>
<li><p>The difference between the frames returned by a decoder transform and
the complementary TorchVision transform are such that a model should
not be able to tell the difference.</p></li>
</ol>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Applying the exact same transforms during training and inference is
important for model perforamnce. For example, if you use decoder
transforms to resize frames during training, you should also use decoder
transforms to resize frames during inference. We provide the similarity
guarantees to mitigate the harm when the two techniques are
<em>unintentionally</em> mixed. That is, if you use decoder transforms to resize
frames during training, but use TorchVisions’s
<a class="reference external" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="(in Torchvision v0.25)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Resize</span></code></a> during inference, our guarantees
mitigate the harm to model performance. But we <strong>reccommend against</strong> this kind of
mixing.</p>
<p>It is appropriate and expected to use some decoder transforms and some TorchVision
transforms, as long as the exact same pre-processing operations are performed during
training and inference.</p>
</div>
</section>
<section id="decoder-transform-pipelines">
<h2>Decoder transform pipelines<a class="headerlink" href="#decoder-transform-pipelines" title="Permalink to this heading">¶</a></h2>
<p>So far, we’ve only provided a single transform to the <code class="docutils literal notranslate"><span class="pre">transform</span></code> parameter to
<a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a>. But it
actually accepts a list of transforms, which become a pipeline of transforms.
The order of the list matters: the first transform in the list will receive
the originally decoded frame. The output of that transform becomes the input
to the next transform in the list, and so on.</p>
<p>From now on, we’ll use TorchCodec transforms instead of TorchVision
transforms. When passed to the <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a>,
they behave identically.</p>
<p>A simple example:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchcodec.transforms</span><span class="w"> </span><span class="kn">import</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">CenterCrop</span></a>


<span class="n">crop_resize_decoder</span> <span class="o">=</span> <span class="n">VideoDecoder</span><span class="p">(</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">,</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
        <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">CenterCrop</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1280</span><span class="p">,</span> <span class="mi">1664</span><span class="p">)),</span>
        <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">)),</span>
    <span class="p">]</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">crop_resized_during</span></a> <span class="o">=</span> <span class="n">crop_resize_decoder</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>
<span class="n">plot</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">crop_resized_during</span></a><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Center cropped then resized to 480x640&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_transforms_003.png" srcset="../../_images/sphx_glr_transforms_003.png" alt="Center cropped then resized to 480x640" class = "sphx-glr-single-img"/></section>
<section id="performance-memory-efficiency-and-speed">
<h2>Performance: memory efficiency and speed<a class="headerlink" href="#performance-memory-efficiency-and-speed" title="Permalink to this heading">¶</a></h2>
<p>The main motivation for decoder transforms is <em>memory efficiency</em>,
particularly when applying transforms that reduce the size of a frame, such
as resize and crop. Because the FFmpeg layer knows all of the transforms it
needs to apply during decoding, it’s able to efficiently reuse memory.
Further, full resolution frames are never returned to the Python layer.  As a
result, there is significantly less total memory needed and less pressure on
the Python garbage collector.</p>
<p>In <a class="reference external" href="https://github.com/meta-pytorch/torchcodec/blob/f6a816190cbcac417338c29d5e6fac99311d054f/benchmarks/decoders/benchmark_transforms.py">benchmarks</a>
reducing frames from (1080, 1920) down to (135, 240), we have observed a
reduction in peak resident set size from 4.3 GB to 0.4 GB.</p>
<p>There is sometimes a runtime benefit, but it is dependent on the number of
threads that the <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> tells FFmpeg
to use. We define the following benchmark function, as well as the functions
to benchmark:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bench</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">average_over</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">f_kwargs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup</span><span class="p">):</span>
        <span class="n">f</span><span class="p">(</span><span class="o">**</span><span class="n">f_kwargs</span><span class="p">)</span>

    <span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">average_over</span><span class="p">):</span>
        <span class="n">start_time</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter_ns" title="time.perf_counter_ns" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">perf_counter_ns</span></a><span class="p">()</span>
        <span class="n">f</span><span class="p">(</span><span class="o">**</span><span class="n">f_kwargs</span><span class="p">)</span>
        <span class="n">end_time</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.perf_counter_ns" title="time.perf_counter_ns" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">perf_counter_ns</span></a><span class="p">()</span>
        <span class="n">times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

    <span class="n">times</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="n">times</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-6</span>  <span class="c1"># ns to ms</span>
    <span class="n">times_std</span> <span class="o">=</span> <span class="n">times</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">times_med</span> <span class="o">=</span> <span class="n">times</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">times_med</span><span class="w"> </span><span class="si">= :</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms +- </span><span class="si">{</span><span class="n">times_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>


<span class="kn">from</span><span class="w"> </span><span class="nn">torchcodec</span><span class="w"> </span><span class="kn">import</span> <span class="n">samplers</span>


<span class="k">def</span><span class="w"> </span><span class="nf">sample_decoder_transforms</span><span class="p">(</span><span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">VideoDecoder</span><span class="p">(</span>
        <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">,</span>
        <span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
            <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">CenterCrop</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1280</span><span class="p">,</span> <span class="mi">1664</span><span class="p">)),</span>
            <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">Resize</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">)),</span>
        <span class="p">],</span>
        <span class="n">seek_mode</span><span class="o">=</span><span class="s2">&quot;approximate&quot;</span><span class="p">,</span>
        <span class="n">num_ffmpeg_threads</span><span class="o">=</span><span class="n">num_threads</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">transformed_frames</span> <span class="o">=</span> <span class="n">samplers</span><span class="o">.</span><span class="n">clips_at_regular_indices</span><span class="p">(</span>
        <span class="n">decoder</span><span class="p">,</span>
        <span class="n">num_clips</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">num_frames_per_clip</span><span class="o">=</span><span class="mi">200</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">transformed_frames</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">200</span>


<span class="k">def</span><span class="w"> </span><span class="nf">sample_torchvision_transforms</span><span class="p">(</span><span class="n">num_threads</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">num_threads</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <a href="https://docs.pytorch.org/docs/stable/generated/torch.set_num_threads.html#torch.set_num_threads" title="torch.set_num_threads" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span></a><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">VideoDecoder</span><span class="p">(</span>
        <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">penguin_video_path</span></a><span class="p">,</span>
        <span class="n">seek_mode</span><span class="o">=</span><span class="s2">&quot;approximate&quot;</span><span class="p">,</span>
        <span class="n">num_ffmpeg_threads</span><span class="o">=</span><span class="n">num_threads</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="n">samplers</span><span class="o">.</span><span class="n">clips_at_regular_indices</span><span class="p">(</span>
        <span class="n">decoder</span><span class="p">,</span>
        <span class="n">num_clips</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">num_frames_per_clip</span><span class="o">=</span><span class="mi">200</span>
    <span class="p">)</span>
    <span class="n">transforms</span> <span class="o">=</span> <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Compose.html#torchvision.transforms.v2.Compose" title="torchvision.transforms.v2.Compose" class="sphx-glr-backref-module-torchvision-transforms-v2 sphx-glr-backref-type-py-class"><span class="n">v2</span><span class="o">.</span><span class="n">Compose</span></a><span class="p">(</span>
        <span class="p">[</span>
            <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.CenterCrop.html#torchvision.transforms.v2.CenterCrop" title="torchvision.transforms.v2.CenterCrop" class="sphx-glr-backref-module-torchvision-transforms-v2 sphx-glr-backref-type-py-class"><span class="n">v2</span><span class="o">.</span><span class="n">CenterCrop</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1280</span><span class="p">,</span> <span class="mi">1664</span><span class="p">)),</span>
            <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="torchvision.transforms.v2.Resize" class="sphx-glr-backref-module-torchvision-transforms-v2 sphx-glr-backref-type-py-class"><span class="n">v2</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">)),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">transformed_frames</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">frames</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">transformed_frames</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">200</span>
</pre></div>
</div>
<p>When the <a class="reference internal" href="../../generated/torchcodec.decoders.VideoDecoder.html#torchcodec.decoders.VideoDecoder" title="torchcodec.decoders.VideoDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoDecoder</span></code></a> object sets the number of
FFmpeg threads to 0, that tells FFmpeg to determine how many threads to use
based on what is available on the current system. In such cases, decoder transforms
will tend to outperform getting back a full frame and applying TorchVision transforms
sequentially:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;decoder transforms:    </span><span class="si">{</span><span class="n">bench</span><span class="p">(</span><span class="n">sample_decoder_transforms</span><span class="p">,</span><span class="w"> </span><span class="n">num_threads</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;torchvision transform: </span><span class="si">{</span><span class="n">bench</span><span class="p">(</span><span class="n">sample_torchvision_transforms</span><span class="p">,</span><span class="w"> </span><span class="n">num_threads</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>decoder transforms:    times_med = 2323.61ms +- 8.40
torchvision transform: times_med = 5273.69ms +- 60.87
</pre></div>
</div>
<p>The reason is that FFmpeg is applying the decoder transforms in parallel.
However, if the number of threads is 1 (as is the default), then there is often
less benefit to using decoder transforms. Using the TorchVision transforms may
even be faster!</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;decoder transforms:    </span><span class="si">{</span><span class="n">bench</span><span class="p">(</span><span class="n">sample_decoder_transforms</span><span class="p">,</span><span class="w"> </span><span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;torchvision transform: </span><span class="si">{</span><span class="n">bench</span><span class="p">(</span><span class="n">sample_torchvision_transforms</span><span class="p">,</span><span class="w"> </span><span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>decoder transforms:    times_med = 15164.38ms +- 27.95
torchvision transform: times_med = 17321.23ms +- 21.20
</pre></div>
</div>
<p>In brief, our performance guidance is:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>If you are applying a transform pipeline that signficantly reduces
the dimensions of your input frames and memory efficiency matters, use
decoder transforms.</p></li>
<li><p>If you are using multiple FFmpeg threads, decoder transforms may be
faster. Experiment with your setup to verify.</p></li>
<li><p>If you are using a single FFmpeg thread, then decoder transforms may
be slower. Experiment with your setup to verify.</p></li>
</ol>
</div></blockquote>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/shutil.html#shutil.rmtree" title="shutil.rmtree" class="sphx-glr-backref-module-shutil sphx-glr-backref-type-py-function"><span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">temp_dir</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (3 minutes 22.610 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-generated-examples-decoding-transforms-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/f189e474be55fc74900ac94fda37f6f0/transforms.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">transforms.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/db26e760d4542baa544da54c0679fa78/transforms.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">transforms.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/f3079e16df0008c9a46cb7597bf0cc72/transforms.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">transforms.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../encoding/index.html" class="btn btn-neutral float-right" title="Encoding" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="custom_frame_mappings.html" class="btn btn-neutral" title="Decoding with custom frame mappings" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023-present, TorchCodec Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Decoder Transforms: Applying transforms during decoding</a><ul>
<li><a class="reference internal" href="#our-example-video">Our example video</a></li>
<li><a class="reference internal" href="#applying-transforms-during-pre-processing">Applying transforms during pre-processing</a></li>
<li><a class="reference internal" href="#torchcodec-s-relationship-to-torchvision-transforms">TorchCodec’s relationship to TorchVision transforms</a></li>
<li><a class="reference internal" href="#decoder-transform-pipelines">Decoder transform pipelines</a></li>
<li><a class="reference internal" href="#performance-memory-efficiency-and-speed">Performance: memory efficiency and speed</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
         <script src="../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<!-- Disabling "auto-collapsing" of sections on the left side bar. Replace script with commented out sections to reenable. -->
<!--  
<script script type="text/javascript">
    var collapsedSections = ['Introduction', 'Getting Started', 'Tutorials']
</script> -->

<script script type="text/javascript">
    var collapsedSections = []
</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>