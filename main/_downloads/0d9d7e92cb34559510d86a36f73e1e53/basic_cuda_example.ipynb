{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Accelerated video decoding on GPUs with CUDA and NVDEC\n\nTorchCodec can use supported Nvidia hardware (see support matrix\n[here](https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new)) to speed-up\nvideo decoding. This is called \"CUDA Decoding\" and it uses Nvidia's\n[NVDEC hardware decoder](https://developer.nvidia.com/video-codec-sdk)\nand CUDA kernels to respectively decompress and convert to RGB.\nCUDA Decoding can be faster than CPU Decoding for the actual decoding step and also for\nsubsequent transform steps like scaling, cropping or rotating. This is because the decode step leaves\nthe decoded tensor in GPU memory so the GPU doesn't have to fetch from main memory before\nrunning the transform steps. Encoded packets are often much smaller than decoded frames so\nCUDA decoding also uses less PCI-e bandwidth.\n\n## Installing TorchCodec with CUDA Enabled\n\nRefer to the installation guide in the [README](https://github.com/pytorch/torchcodec#installing-cuda-enabled-torchcodec).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checking if Pytorch has CUDA enabled\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This tutorial requires FFmpeg libraries compiled with CUDA support.</p></div>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nprint(f\"{torch.__version__=}\")\nprint(f\"{torch.cuda.is_available()=}\")\nprint(f\"{torch.cuda.get_device_properties(0)=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading the video\n\nWe will use the following video which has the following properties:\n\n- Codec: H.264\n- Resolution: 960x540\n- FPS: 29.97\n- Pixel format: YUV420P\n\n.. raw:: html\n\n   <video style=\"max-width: 100%\" controls>\n     <source src=\"https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4_small.mp4\" type=\"video/mp4\">\n   </video>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import urllib.request\n\nvideo_file = \"video.mp4\"\nurllib.request.urlretrieve(\n    \"https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4_small.mp4\",\n    video_file,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CUDA Decoding using VideoDecoder\n\nTo use CUDA decoder, you need to pass in a cuda device to the decoder.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchcodec.decoders import set_cuda_backend, VideoDecoder\n\nwith set_cuda_backend(\"beta\"):  # Use the BETA backend, it's faster!\n    decoder = VideoDecoder(video_file, device=\"cuda\")\nframe = decoder[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The video frames are decoded and returned as tensor of NCHW format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(frame.shape, frame.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The video frames are left on the GPU memory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(frame.data.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checking for CPU Fallback\n\nIn some cases, CUDA decoding may fall back to CPU decoding. This can happen\nwhen the video codec or format is not supported by the NVDEC hardware decoder, or when NVCUVID wasn't found.\nTorchCodec provides the :class:`~torchcodec.decoders.CpuFallbackStatus` class\nto help you detect when this fallback occurs.\n\nYou can access the fallback status via the\n:attr:`~torchcodec.decoders.VideoDecoder.cpu_fallback` attribute:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with set_cuda_backend(\"beta\"):\n    decoder = VideoDecoder(video_file, device=\"cuda\")\n\n# Check and print the CPU fallback status\nprint(decoder.cpu_fallback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Frames\n\nLet's look at the frames decoded by CUDA decoder and compare them\nagainst equivalent results from the CPU decoders.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timestamps = [12, 19, 45, 131, 180]\ncpu_decoder = VideoDecoder(video_file, device=\"cpu\")\nwith set_cuda_backend(\"beta\"):\n    cuda_decoder = VideoDecoder(video_file, device=\"cuda\")\ncpu_frames = cpu_decoder.get_frames_played_at(timestamps).data\ncuda_frames = cuda_decoder.get_frames_played_at(timestamps).data\n\n\ndef plot_cpu_and_cuda_frames(cpu_frames: torch.Tensor, cuda_frames: torch.Tensor):\n    try:\n        import matplotlib.pyplot as plt\n        from torchvision.transforms.v2.functional import to_pil_image\n    except ImportError:\n        print(\"Cannot plot, please run `pip install torchvision matplotlib`\")\n        return\n    n_rows = len(timestamps)\n    fig, axes = plt.subplots(n_rows, 2, figsize=[12.8, 16.0])\n    for i in range(n_rows):\n        axes[i][0].imshow(to_pil_image(cpu_frames[i].to(\"cpu\")))\n        axes[i][1].imshow(to_pil_image(cuda_frames[i].to(\"cpu\")))\n\n    axes[0][0].set_title(\"CPU decoder\", fontsize=24)\n    axes[0][1].set_title(\"CUDA decoder\", fontsize=24)\n    plt.setp(axes, xticks=[], yticks=[])\n    plt.tight_layout()\n\n\nplot_cpu_and_cuda_frames(cpu_frames, cuda_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "They look visually similar to the human eye but there may be subtle\ndifferences because CUDA math is not bit-exact with respect to CPU math.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "frames_equal = torch.equal(cpu_frames.to(\"cuda\"), cuda_frames)\nmean_abs_diff = torch.mean(\n    torch.abs(cpu_frames.float().to(\"cuda\") - cuda_frames.float())\n)\nmax_abs_diff = torch.max(torch.abs(cpu_frames.to(\"cuda\").float() - cuda_frames.float()))\nprint(f\"{frames_equal=}\")\nprint(f\"{mean_abs_diff=}\")\nprint(f\"{max_abs_diff=}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}